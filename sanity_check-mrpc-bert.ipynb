{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "private-retailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from newlm.lm.bert.lm_builder import LMBuilder\n",
    "from transformers import BertForMaskedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-retrieval",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "handmade-history",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./outputs/en.100-percent.bert.1M\"\n",
    "config_path = 'examples/configs_gcloud/run.100-percent.yaml'\n",
    "model_type = \"bert\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proper-coral",
   "metadata": {},
   "source": [
    "### Model Bert Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "pending-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForMaskedLM.from_pretrained(\n",
    "    model_path\n",
    ") # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "considerable-listening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(\"model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "distinguished-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "urban-tender",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "opening-jackson",
   "metadata": {},
   "source": [
    "#### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "legitimate-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "from newlm.utils.file_util import read_from_yaml\n",
    "config_file = read_from_yaml(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "virgin-cursor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer (helper)\n",
    "from transformers import TrainingArguments, Trainer\n",
    "trainer_args = TrainingArguments(output_dir=\"tmpout\",**config_file['lm']['hf_trainer']['args'])\n",
    "\n",
    "# lm builder (helper)\n",
    "lm_builder = LMBuilder(\n",
    "    model_config = config_file['lm']['model']['config'],\n",
    "    tokenizer=model_path, # use pre-trained tokenizer\n",
    "    max_len=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "brilliant-knitting",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from newlm.glue.cls_trainer import ClsTrainer\n",
    "cls_trainer = ClsTrainer(\n",
    "    model_path,\n",
    "    model_path,\n",
    "    model_type=model_type\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improving-exposure",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "naval-foundation",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "ds_ori = cls_trainer.helper(\"mrpc\", {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "textile-diary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " \"Yucaipa owned Dominick 's before selling the chain to Safeway in 1998 for $ 2.5 billion .\",\n",
       " 'They had published an advertisement on the Internet on June 10 , offering the cargo for sale , he added .']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_ori['train']['sentence1'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rocky-commitment",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 17:44:01.440 | INFO     | newlm.glue.cls_trainer:helper:71 - Use detokenizer moses\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "ds_moses = cls_trainer.helper(\"mrpc\", {\"detokenizer\": \"moses\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "democratic-travel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amrozi accused his brother, whom he called \"the witness\", of deliberately distorting his evidence.',\n",
       " \"Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\",\n",
       " 'They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_moses['train']['sentence1'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "stunning-amateur",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-01 17:44:09.155 | INFO     | newlm.glue.cls_trainer:helper:71 - Use detokenizer treebank\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "ds_tb = cls_trainer.helper(\"mrpc\", {\"detokenizer\": \"treebank\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "manufactured-sheep",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Amrozi accused his brother, whom he called \" the witness \", of deliberately distorting his evidence.',\n",
       " \"Yucaipa owned Dominick's before selling the chain to Safeway in 1998 for $2.5 billion.\",\n",
       " 'They had published an advertisement on the Internet on June 10, offering the cargo for sale, he added.']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_tb['train']['sentence1'][:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "overall-bunny",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: idx, sentence2, sentence1.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=trainer_args, data_collator=lm_builder.data_collator, train_dataset=ds_ori['train'])\n",
    "dl_ori = trainer.get_train_dataloader() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "identical-decade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: idx, sentence2, sentence1.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=trainer_args, data_collator=lm_builder.data_collator, train_dataset=ds_moses['train'])\n",
    "dl_moses = trainer.get_train_dataloader() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "extreme-stack",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "The following columns in the training set  don't have a corresponding argument in `BertForMaskedLM.forward` and have been ignored: idx, sentence2, sentence1.\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=model, args=trainer_args, data_collator=lm_builder.data_collator, train_dataset=ds_tb['train'])\n",
    "dl_tb = trainer.get_train_dataloader() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separate-trinidad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "sufficient-workplace",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_ori = next(iter(dl_ori))\n",
    "batch_moses = next(iter(dl_moses))\n",
    "batch_tb = next(iter(dl_tb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-correspondence",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "olive-fault",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(\"model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optical-stevens",
   "metadata": {},
   "source": [
    "### RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "compound-introduction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  1785,  3719,  ...,  2100,    18,     3],\n",
       "        [    2,  1771,  2957,  ...,     0,     0,     0],\n",
       "        [    2,  1771, 19714,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,  9344,    11,  ...,     0,     0,     0],\n",
       "        [    2,  1833,  6441,  ...,     0,     0,     0],\n",
       "        [    2,  2195,  4241,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del batch_ori['label']\n",
    "batch_ori['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "posted-probe",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_ori = model(**batch_ori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "demanding-consumer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.7566, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_ori.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "particular-rubber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  1785,  3719,  ...,  2100,    18,     3],\n",
       "        [    2,  1771,     4,  ...,     0,     0,     0],\n",
       "        [    2,  1771, 19714,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,     4,    11,  ...,     0,     0,     0],\n",
       "        [    2,  1833,  6441,  ...,     0,     0,     0],\n",
       "        [    2,  2195,  4241,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del batch_moses['label']\n",
    "batch_moses['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "mental-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_moses = model(**batch_moses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "brief-support",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5716, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_moses.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "brutal-potato",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  1785,  3719,  ...,  2100,     4,     3],\n",
       "        [    2,  1771,  2957,  ...,     0,     0,     0],\n",
       "        [    2,  1771, 19714,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,  9344,     4,  ...,     0,     0,     0],\n",
       "        [    2,  1833,  5491,  ...,     0,     0,     0],\n",
       "        [    2,  2195,  4241,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del batch_tb['label']\n",
    "batch_tb['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "through-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tb = model(**batch_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "consistent-scratch",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5242, grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_tb.loss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
