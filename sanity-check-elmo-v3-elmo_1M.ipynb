{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "forced-rugby",
   "metadata": {},
   "source": [
    "# Sanity Check ELMO Bert-Causal vs Bert-Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "checked-player",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "worth-leonard",
   "metadata": {},
   "source": [
    "## Prepare Data + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arabic-creation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rødberg is located in the Norwegian traditional district and valley of Numedal .\n",
      "The plants are affiliated with Statkraft , the Norwegian state owned electricity company .\n",
      "The final passenger service ended in 1988 . The rail line north of Rollag was closed in 1989 .\n",
      "\n",
      "Persecution of Jews in Europe increased in the High Middle Ages in the context of the Christian Crusades .\n",
      "In 1394 , 100 , 000 Jews were expelled from France .\n",
      "Jews were indeed infected in numbers similar to their non - Jewish neighbors Yet they were still made scapegoats .\n",
      "Jewish daily life was very satisfying .\n",
      "Jews lived among Jews .\n"
     ]
    }
   ],
   "source": [
    "!cat ./examples/data/text_forward-small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "major-feature",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "indie-contrast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from newlm.lm.elmo.modeling_elmo.elmo_head import ELMOBertLMHeadModel\n",
    "from newlm.lm.elmo.lm_builder import ELMOLMBuilder\n",
    "from transformers import BertConfig, BertLMHeadModel\n",
    "from newlm.utils.file_util import read_from_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alien-thinking",
   "metadata": {},
   "source": [
    "#### Model Bert Causal 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "thorough-stephen",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_bc = \"./outputs/en.100-percent.bert-causal.1M\"\n",
    "config_bc = read_from_yaml('examples/configs_gcloud/run-100-percent.bert-causal.yaml')\n",
    "\n",
    "model_bc = BertLMHeadModel.from_pretrained(pt_bc) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "greenhouse-turkey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_bc.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "familiar-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-orientation",
   "metadata": {},
   "source": [
    "#### Model ELMO Bert Causal 1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "forty-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_elmo = \"./outputs/en.100-percent.elmo-bert-causal.1M\"\n",
    "config_elmo = read_from_yaml('examples/configs_gcloud/run-100-percent.elmo-bert-causal.yaml')\n",
    "\n",
    "model_elmo = ELMOBertLMHeadModel.from_pretrained(pt_elmo) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "proud-intelligence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_elmo.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "strategic-breath",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_elmo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjacent-lawsuit",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "indie-pressing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(config_file, tokenizer_dir, model_type, model):\n",
    "    # lm builder (helper)\n",
    "    elmo_lm_builder = ELMOLMBuilder(\n",
    "        model_config = config_file['lm']['model']['config'],\n",
    "        tokenizer=tokenizer_dir,\n",
    "        model_type=model_type,\n",
    "        max_len=128\n",
    "    )\n",
    "    \n",
    "    # dataset-forward\n",
    "    train_path = \"./examples/data/text_forward-small.txt\"\n",
    "    ds_f = elmo_lm_builder._get_dataset(train_path)\n",
    "    \n",
    "    # trainer (helper)\n",
    "    from transformers import TrainingArguments, Trainer\n",
    "    args = TrainingArguments(output_dir=\"tmpout\",**config_file['lm']['hf_trainer']['args'])\n",
    "\n",
    "    # dataloader-forward\n",
    "    trainer = Trainer(model=model, args=args, data_collator=elmo_lm_builder.data_collator, train_dataset=ds_f)\n",
    "    dl_f = trainer.get_train_dataloader() # Data Loader-forward\n",
    "    \n",
    "    \n",
    "    return dl_f, elmo_lm_builder.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-gamma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "respiratory-stupid",
   "metadata": {},
   "source": [
    "#### Data for ELMO Bert-Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "motivated-modeling",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 11:49:44.560 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:142 - Constructing roBERTa style dataset\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "dl_elmo, tknz_elmo = get_dataloader(config_elmo, pt_elmo, \"elmo-bert-causal\", model_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "artistic-stuart",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 123])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_elmo = next(iter(dl_elmo))\n",
    "batch_elmo['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-remove",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "controlling-zealand",
   "metadata": {},
   "source": [
    "#### Data for Bert-Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ultimate-resource",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./outputs/en.100-percent.bert-causal.1M/tokenizer.json. We won't load it.\n",
      "Didn't find file ./outputs/en.100-percent.bert-causal.1M/added_tokens.json. We won't load it.\n",
      "Didn't find file ./outputs/en.100-percent.bert-causal.1M/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./outputs/en.100-percent.bert-causal.1M/tokenizer_config.json. We won't load it.\n",
      "loading file ./outputs/en.100-percent.bert-causal.1M/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ./outputs/en.100-percent.bert-causal.1M/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertLMHeadModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading configuration file ./outputs/en.100-percent.bert-causal.1M/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertLMHeadModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "2021-12-27 11:49:46.033 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:142 - Constructing roBERTa style dataset\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "dl_bc, tknz_bc = get_dataloader(config_bc, pt_bc, \"bert-causal\", model_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "colored-ottawa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 123])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_bc = next(iter(dl_bc))\n",
    "batch_bc['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-collins",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "three-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_batch(batch_f, tknz):\n",
    "    tokens_f = tknz.convert_ids_to_tokens(batch_f['input_ids'][0])\n",
    "    return pd.DataFrame({\"data\": tokens_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "sized-assurance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Jews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        data\n",
       "0      [CLS]\n",
       "1      [UNK]\n",
       "2         is\n",
       "3    located\n",
       "4         in\n",
       "..       ...\n",
       "118    lived\n",
       "119    among\n",
       "120     Jews\n",
       "121        .\n",
       "122    [SEP]\n",
       "\n",
       "[123 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_batch(batch_elmo, tknz_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "simplified-universal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[UNK]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>located</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>Jews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        data\n",
       "0      [CLS]\n",
       "1      [UNK]\n",
       "2         is\n",
       "3    located\n",
       "4         in\n",
       "..       ...\n",
       "118    lived\n",
       "119    among\n",
       "120     Jews\n",
       "121        .\n",
       "122    [SEP]\n",
       "\n",
       "[123 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_batch(batch_bc, tknz_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-image",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "worldwide-dancing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_elmo.eval()\n",
    "model_bc.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "trying-melbourne",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "emotional-hypothesis",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "young-arrival",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2r_loss tensor(3.9105, grad_fn=<NllLossBackward>)\n",
      "r2l_loss tensor(3.8871, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#### ELMO BERT-Causal\n",
    "res = model_elmo(**batch_elmo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fewer-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2r_loss tensor(3.9318, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#### Bert-Causal\n",
    "res = model_bc(**batch_bc)\n",
    "print(\"l2r_loss\", res.loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
