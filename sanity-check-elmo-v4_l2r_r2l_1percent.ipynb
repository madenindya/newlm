{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "speaking-responsibility",
   "metadata": {},
   "source": [
    "# Sanity Check Bert-Causal L2R vs R2L using model 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-dress",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "removable-burden",
   "metadata": {},
   "source": [
    "## Prepare Data + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "loving-album",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rødberg is located in the Norwegian traditional district and valley of Numedal .\n",
      "The plants are affiliated with Statkraft , the Norwegian state owned electricity company .\n",
      "The final passenger service ended in 1988 . The rail line north of Rollag was closed in 1989 .\n",
      "\n",
      "Persecution of Jews in Europe increased in the High Middle Ages in the context of the Christian Crusades .\n",
      "In 1394 , 100 , 000 Jews were expelled from France .\n",
      "Jews were indeed infected in numbers similar to their non - Jewish neighbors Yet they were still made scapegoats .\n",
      "Jewish daily life was very satisfying .\n",
      "Jews lived among Jews .\n"
     ]
    }
   ],
   "source": [
    "!cat ./examples/data/text_forward-small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-carry",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mexican-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from newlm.lm.elmo.lm_builder import ELMOLMBuilder\n",
    "\n",
    "from newlm.lm.elmo.modeling_elmo.elmo_head import ELMOBertLMHeadModel\n",
    "from transformers import BertConfig, BertLMHeadModel\n",
    "from newlm.lm.bert.modeling_bert.bert_head import BertLMHeadR2LModel\n",
    "\n",
    "from newlm.utils.file_util import read_from_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collected-hazard",
   "metadata": {},
   "source": [
    "#### Model Bert Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "extraordinary-utilization",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_l2r = \"./outputs/en.1-percent.bert-causal\"\n",
    "config_l2r = read_from_yaml('examples/configs/run.1-percent-bert-causal.yaml')\n",
    "config_l2r[\"lm\"][\"model_type\"] = 'bert-causal'\n",
    "\n",
    "model_l2r = BertLMHeadModel.from_pretrained(pt_l2r) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "artificial-employer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_l2r.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stunning-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_r2l = \"./outputs/en.1-percent.bert-causal-r2l\"\n",
    "config_r2l = read_from_yaml('examples/configs/run.1-percent-bert-causal.yaml')\n",
    "config_r2l[\"lm\"][\"model_type\"] = 'bert-causal-r2l'\n",
    "\n",
    "model_r2l = BertLMHeadR2LModel.from_pretrained(pt_r2l) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "american-shift",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_r2l.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scientific-jacket",
   "metadata": {},
   "source": [
    "#### Model ELMO Bert Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "based-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_elmo = \"./outputs/en.1-percent.elmo-bert-causal\"\n",
    "config_elmo = read_from_yaml('examples/configs/run.1-percent-elmo-bert-causal.yaml')\n",
    "\n",
    "model_elmo = ELMOBertLMHeadModel.from_pretrained(pt_elmo) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "overall-arabic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_elmo.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "binary-catalog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_l2r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "polish-drama",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_r2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-accent",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "freelance-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(config_file, tokenizer_dir, model_type, model):\n",
    "    # lm builder (helper)\n",
    "    elmo_lm_builder = ELMOLMBuilder(\n",
    "        model_config = config_file['lm']['model']['config'],\n",
    "        tokenizer=tokenizer_dir,\n",
    "        model_type=model_type,\n",
    "        max_len=128\n",
    "    )\n",
    "    \n",
    "    # dataset-forward\n",
    "    train_path = \"./examples/data/text_forward-small.txt\"\n",
    "    ds_f = elmo_lm_builder._get_dataset(train_path)\n",
    "    \n",
    "    # trainer (helper)\n",
    "    from transformers import TrainingArguments, Trainer\n",
    "    args = TrainingArguments(output_dir=\"tmpout\",**config_file['lm']['hf_trainer']['args'])\n",
    "\n",
    "    # dataloader-forward\n",
    "    trainer = Trainer(model=model, args=args, data_collator=elmo_lm_builder.data_collator, train_dataset=ds_f)\n",
    "    dl_f = trainer.get_train_dataloader() # Data Loader-forward\n",
    "    \n",
    "    \n",
    "    return dl_f, elmo_lm_builder.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cheap-singing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "marked-europe",
   "metadata": {},
   "source": [
    "#### Data for Bert-Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "determined-illustration",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 17:02:31.434 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:145 - Constructing roBERTa style dataset\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/tokenizer.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/added_tokens.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/tokenizer_config.json. We won't load it.\n",
      "loading file ./outputs/en.1-percent.bert-causal-r2l/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ./outputs/en.1-percent.bert-causal-r2l/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertLMHeadR2LModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading configuration file ./outputs/en.1-percent.bert-causal-r2l/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertLMHeadR2LModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "2022-01-08 17:02:33.223 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:145 - Constructing roBERTa style dataset\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "dl_l2r, tknz_l2r = get_dataloader(config_l2r, pt_l2r, \"bert-causal\", model_l2r)\n",
    "dl_r2l, tknz_r2l = get_dataloader(config_r2l, pt_r2l, \"bert-causal-r2l\", model_r2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "indie-blackberry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_l2r = next(iter(dl_l2r))\n",
    "batch_l2r['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "impressive-baker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_r2l = next(iter(dl_r2l))\n",
    "batch_r2l['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "naughty-vegetation",
   "metadata": {},
   "source": [
    "#### Data for ELMO Bert-Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "permanent-importance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/tokenizer.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/added_tokens.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/tokenizer_config.json. We won't load it.\n",
      "loading file ./outputs/en.1-percent.elmo-bert-causal/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ./outputs/en.1-percent.elmo-bert-causal/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"ELMOBertLMHeadModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading configuration file ./outputs/en.1-percent.elmo-bert-causal/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"ELMOBertLMHeadModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "2022-01-08 17:02:34.821 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:145 - Constructing roBERTa style dataset\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "dl_elmo, tknz_elmo = get_dataloader(config_elmo, pt_elmo, \"elmo-bert-causal\", model_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "electoral-field",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_elmo = next(iter(dl_elmo))\n",
    "batch_elmo['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comic-wallace",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "confident-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_batch(batch_f, tknz):\n",
    "    tokens_f = tknz.convert_ids_to_tokens(batch_f['input_ids'][0])\n",
    "    return pd.DataFrame({\"data\": tokens_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "criminal-consensus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2r</th>\n",
       "      <th>r2l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##ø</td>\n",
       "      <td>##ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##d</td>\n",
       "      <td>##d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##berg</td>\n",
       "      <td>##berg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>lived</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>among</td>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Jews</td>\n",
       "      <td>Jews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        l2r     r2l\n",
       "0     [CLS]   [CLS]\n",
       "1         R       R\n",
       "2       ##ø     ##ø\n",
       "3       ##d     ##d\n",
       "4    ##berg  ##berg\n",
       "..      ...     ...\n",
       "122   lived   lived\n",
       "123   among   among\n",
       "124    Jews    Jews\n",
       "125       .       .\n",
       "126   [SEP]   [SEP]\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_l2r = print_batch(batch_l2r, tknz_l2r)\n",
    "df_r2l = print_batch(batch_r2l, tknz_r2l)\n",
    "pd.DataFrame({\"l2r\": df_l2r['data'], \"r2l\": df_r2l[\"data\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aware-toner",
   "metadata": {},
   "source": [
    "Same input (forward) for L2R and R2L. The R2L input would be flipped inside forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "strong-louisiana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##ø</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##berg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Jews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       data\n",
       "0     [CLS]\n",
       "1         R\n",
       "2       ##ø\n",
       "3       ##d\n",
       "4    ##berg\n",
       "..      ...\n",
       "122   lived\n",
       "123   among\n",
       "124    Jews\n",
       "125       .\n",
       "126   [SEP]\n",
       "\n",
       "[127 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_batch(batch_elmo, tknz_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-perspective",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "quiet-medication",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_elmo.eval()\n",
    "model_l2r.eval()\n",
    "model_r2l.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "orange-wagon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "indie-temperature",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "former-worship",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "res_l2r = model_l2r(**batch_l2r)\n",
    "res_r2l = model_r2l(**batch_r2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "departmental-spiritual",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2r_loss tensor(4.3849, grad_fn=<NllLossBackward>)\n",
      "r2l_loss tensor(4.4385, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "print(\"l2r_loss\", res_l2r.loss)\n",
    "print(\"r2l_loss\", res_r2l.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "artificial-compatibility",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP Bert-Causal l2r tensor([80.2302])\n",
      "PP Bert-Causal r2l tensor([84.6479])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PP Bert-Causal l2r\", torch.exp(torch.Tensor([4.3849])))\n",
    "print(\"PP Bert-Causal r2l\", torch.exp(torch.Tensor([4.4385])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-uruguay",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "driven-context",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2r_loss tensor(4.4801, grad_fn=<NllLossBackward>)\n",
      "r2l_loss tensor(4.3589, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#### ELMO BERT-Causal\n",
    "res_elmo = model_elmo(**batch_elmo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "normal-reason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP ELMO Bert-Causal l2r tensor([88.2435])\n",
      "PP ELMO Bert-Causal r2l tensor([78.1711])\n"
     ]
    }
   ],
   "source": [
    "print(\"PP ELMO Bert-Causal l2r\", torch.exp(torch.Tensor([4.4801])))\n",
    "print(\"PP ELMO Bert-Causal r2l\", torch.exp(torch.Tensor([4.3589])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-chaos",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "temporal-characteristic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original L2R\n",
      "{'input_ids': tensor([[    2,    54,  1100,  1007,  4854,  1833,  3234,  1783,  1765,  9456,\n",
      "          5718,  3829,  1782,  8725,  1780, 20592, 17660,  1020,    18,  1811,\n",
      "          7614,  1928, 13083,  1827,  9643,  1008,  3438,    16,  1765,  9456,\n",
      "          3054,  5167, 11056,  3204,    18,  1811,  3378,  8418,  3818,  4663,\n",
      "          1783,  5628,    18,  1811,  4155,  2982,  3456,  1780, 11448,  1855,\n",
      "          1795,  3403,  1783,  5546,    18,     3, 27648, 14056,  1792,  1780,\n",
      "          7581,  1783,  3370,  5928,  1783,  1765,  3550,  6677, 16024,  1783,\n",
      "          1765, 10694,  1780,  1765,  4629, 17474,  4456,    18,  1909, 17911,\n",
      "          1045,    16,  3761,    16,  2956,  7581,  1905, 17193,  1868,  4164,\n",
      "            18,  7581,  1905,  8576, 15844,  1783,  6188,  4048,  1779,  2021,\n",
      "          3676,    17,  6273, 15442,  8479,  1983,  1905,  2292,  2202,  2049,\n",
      "          3226,  4141,  3034,    18,  6273,  8319,  2459,  1795,  2485, 22558,\n",
      "            18,  7581,  4369,  3543,  7581,    18,     3]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[    2,    54,  1100,  1007,  4854,  1833,  3234,  1783,  1765,  9456,\n",
      "          5718,  3829,  1782,  8725,  1780, 20592, 17660,  1020,    18,  1811,\n",
      "          7614,  1928, 13083,  1827,  9643,  1008,  3438,    16,  1765,  9456,\n",
      "          3054,  5167, 11056,  3204,    18,  1811,  3378,  8418,  3818,  4663,\n",
      "          1783,  5628,    18,  1811,  4155,  2982,  3456,  1780, 11448,  1855,\n",
      "          1795,  3403,  1783,  5546,    18,     3, 27648, 14056,  1792,  1780,\n",
      "          7581,  1783,  3370,  5928,  1783,  1765,  3550,  6677, 16024,  1783,\n",
      "          1765, 10694,  1780,  1765,  4629, 17474,  4456,    18,  1909, 17911,\n",
      "          1045,    16,  3761,    16,  2956,  7581,  1905, 17193,  1868,  4164,\n",
      "            18,  7581,  1905,  8576, 15844,  1783,  6188,  4048,  1779,  2021,\n",
      "          3676,    17,  6273, 15442,  8479,  1983,  1905,  2292,  2202,  2049,\n",
      "          3226,  4141,  3034,    18,  6273,  8319,  2459,  1795,  2485, 22558,\n",
      "            18,  7581,  4369,  3543,  7581,    18,     3]])}\n",
      "Flip to R2L\n",
      "{'input_ids': tensor([[    3,    18,  7581,  3543,  4369,  7581,    18, 22558,  2485,  1795,\n",
      "          2459,  8319,  6273,    18,  3034,  4141,  3226,  2049,  2202,  2292,\n",
      "          1905,  1983,  8479, 15442,  6273,    17,  3676,  2021,  1779,  4048,\n",
      "          6188,  1783, 15844,  8576,  1905,  7581,    18,  4164,  1868, 17193,\n",
      "          1905,  7581,  2956,    16,  3761,    16,  1045, 17911,  1909,    18,\n",
      "          4456, 17474,  4629,  1765,  1780, 10694,  1765,  1783, 16024,  6677,\n",
      "          3550,  1765,  1783,  5928,  3370,  1783,  7581,  1780,  1792, 14056,\n",
      "         27648,     3,    18,  5546,  1783,  3403,  1795,  1855, 11448,  1780,\n",
      "          3456,  2982,  4155,  1811,    18,  5628,  1783,  4663,  3818,  8418,\n",
      "          3378,  1811,    18,  3204, 11056,  5167,  3054,  9456,  1765,    16,\n",
      "          3438,  1008,  9643,  1827, 13083,  1928,  7614,  1811,    18,  1020,\n",
      "         17660, 20592,  1780,  8725,  1782,  3829,  5718,  9456,  1765,  1783,\n",
      "          3234,  1833,  4854,  1007,  1100,    54,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]]), 'labels': tensor([[    3,    18,  7581,  3543,  4369,  7581,    18, 22558,  2485,  1795,\n",
      "          2459,  8319,  6273,    18,  3034,  4141,  3226,  2049,  2202,  2292,\n",
      "          1905,  1983,  8479, 15442,  6273,    17,  3676,  2021,  1779,  4048,\n",
      "          6188,  1783, 15844,  8576,  1905,  7581,    18,  4164,  1868, 17193,\n",
      "          1905,  7581,  2956,    16,  3761,    16,  1045, 17911,  1909,    18,\n",
      "          4456, 17474,  4629,  1765,  1780, 10694,  1765,  1783, 16024,  6677,\n",
      "          3550,  1765,  1783,  5928,  3370,  1783,  7581,  1780,  1792, 14056,\n",
      "         27648,     3,    18,  5546,  1783,  3403,  1795,  1855, 11448,  1780,\n",
      "          3456,  2982,  4155,  1811,    18,  5628,  1783,  4663,  3818,  8418,\n",
      "          3378,  1811,    18,  3204, 11056,  5167,  3054,  9456,  1765,    16,\n",
      "          3438,  1008,  9643,  1827, 13083,  1928,  7614,  1811,    18,  1020,\n",
      "         17660, 20592,  1780,  8725,  1782,  3829,  5718,  9456,  1765,  1783,\n",
      "          3234,  1833,  4854,  1007,  1100,    54,     2]]), 'inputs_embeds': None}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=tensor(4.4385, grad_fn=<NllLossBackward>), logits=tensor([[[-7.6350,  2.8295,  4.7944,  ..., -3.1778, -2.5064, -2.4032],\n",
       "         [-7.9487,  0.1907, -0.6603,  ..., -3.8263, -4.2424, -3.2813],\n",
       "         [-7.8663,  0.1811,  1.2252,  ..., -6.0053, -2.7640, -3.0149],\n",
       "         ...,\n",
       "         [-5.2620,  2.7503,  3.8883,  ...,  0.9219,  1.1852,  0.7565],\n",
       "         [-7.2864,  2.0949, 14.6970,  ..., -2.6282,  0.7408, -0.8565],\n",
       "         [-5.4013,  2.5424, 20.6766,  ...,  0.1895, -1.1299, -1.9379]]],\n",
       "       grad_fn=<AddBackward0>), past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_r2l(**batch_r2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "reflected-floating",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L2R Input\n",
      "{'input_ids': tensor([[    2,    54,  1072,  1017,  4856,  1835,  3236,  1785,  1767,  9458,\n",
      "          5720,  3831,  1784,  8727,  1782, 20594, 17662,  1012,    18,  1813,\n",
      "          7616,  1930, 13085,  1829,  9645,  1010,  3440,    16,  1767,  9458,\n",
      "          3056,  5169, 11058,  3206,    18,  1813,  3380,  8420,  3820,  4665,\n",
      "          1785,  5630,    18,  1813,  4157,  2984,  3458,  1782, 11450,  1857,\n",
      "          1797,  3405,  1785,  5548,    18,     3, 27650, 14057,  1794,  1782,\n",
      "          7583,  1785,  3372,  5930,  1785,  1767,  3552,  6679, 16026,  1785,\n",
      "          1767, 10696,  1782,  1767,  4631, 17476,  4458,    18,  1911, 17912,\n",
      "          1061,    16,  3763,    16,  2958,  7583,  1907, 17195,  1870,  4166,\n",
      "            18,  7583,  1907,  8578, 15846,  1785,  6190,  4050,  1781,  2023,\n",
      "          3678,    17,  6275, 15444,  8481,  1985,  1907,  2294,  2204,  2051,\n",
      "          3228,  4143,  3036,    18,  6275,  8321,  2461,  1797,  2487, 22560,\n",
      "            18,  7583,  4371,  3545,  7583,    18,     3]]), 'past_key_values': None, 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': None, 'position_ids': None, 'head_mask': None, 'inputs_embeds': None, 'use_cache': None, 'output_attentions': None, 'output_hidden_states': None, 'return_dict': None}\n",
      "R2L Input\n",
      "{'input_ids': tensor([[    3,    18,  7583,  3545,  4371,  7583,    18, 22560,  2487,  1797,\n",
      "          2461,  8321,  6275,    18,  3036,  4143,  3228,  2051,  2204,  2294,\n",
      "          1907,  1985,  8481, 15444,  6275,    17,  3678,  2023,  1781,  4050,\n",
      "          6190,  1785, 15846,  8578,  1907,  7583,    18,  4166,  1870, 17195,\n",
      "          1907,  7583,  2958,    16,  3763,    16,  1061, 17912,  1911,    18,\n",
      "          4458, 17476,  4631,  1767,  1782, 10696,  1767,  1785, 16026,  6679,\n",
      "          3552,  1767,  1785,  5930,  3372,  1785,  7583,  1782,  1794, 14057,\n",
      "         27650,     3,    18,  5548,  1785,  3405,  1797,  1857, 11450,  1782,\n",
      "          3458,  2984,  4157,  1813,    18,  5630,  1785,  4665,  3820,  8420,\n",
      "          3380,  1813,    18,  3206, 11058,  5169,  3056,  9458,  1767,    16,\n",
      "          3440,  1010,  9645,  1829, 13085,  1930,  7616,  1813,    18,  1012,\n",
      "         17662, 20594,  1782,  8727,  1784,  3831,  5720,  9458,  1767,  1785,\n",
      "          3236,  1835,  4856,  1017,  1072,    54,     2]]), 'past_key_values': None, 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1]]), 'token_type_ids': None, 'position_ids': None, 'head_mask': None, 'inputs_embeds': None, 'use_cache': None, 'output_attentions': None, 'output_hidden_states': None, 'return_dict': None}\n",
      "l2r_loss tensor(4.4801, grad_fn=<NllLossBackward>)\n",
      "r2l_loss tensor(4.3589, grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ElmoGPTCausalLMOutput(loss=tensor(8.8390, grad_fn=<AddBackward0>), logits=None, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None, l2r_hidden_states=None, r2l_hidden_states=None, l2r_logits=tensor([[[-7.2616,  2.7625, -6.6354,  ...,  0.0755,  1.3210,  1.4225],\n",
       "         [-4.2509,  3.7727, -4.6725,  ...,  0.2850, -1.1770,  0.3096],\n",
       "         [-6.0543,  0.6120, -5.8872,  ..., -0.0918, -3.1188, -3.3738],\n",
       "         ...,\n",
       "         [-9.5750,  2.8917, -9.0198,  ..., -2.6988, -4.2076, -4.2855],\n",
       "         [-6.2482,  2.5143, -6.2989,  ..., -1.6477,  1.0244, -2.7994],\n",
       "         [-5.5948,  2.1233, -6.3670,  ..., -0.8482,  0.5466, -0.8888]]],\n",
       "       grad_fn=<UnsafeViewBackward>), r2l_logits=tensor([[[-7.0511,  2.5356,  4.3553,  ..., -4.7546, -0.8196, -4.1463],\n",
       "         [-8.4824,  0.5386, -1.8902,  ..., -3.4352, -2.3649, -3.6365],\n",
       "         [-8.0600,  0.3871,  1.8165,  ..., -3.3751, -4.1591, -4.9914],\n",
       "         ...,\n",
       "         [-5.3477,  1.0564,  2.8627,  ...,  0.5925, -3.5095, -0.2700],\n",
       "         [-6.5615,  2.8416, 16.2041,  ..., -1.3201, -2.6620, -2.5944],\n",
       "         [-7.2010,  2.1553, 21.6598,  ..., -2.6696,  1.7202, -3.2762]]],\n",
       "       grad_fn=<UnsafeViewBackward>))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_elmo(**batch_elmo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
