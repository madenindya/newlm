{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "northern-italic",
   "metadata": {},
   "source": [
    "# Sanity Check Bert-Causal L2R vs R2L using model 1%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authentic-sixth",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "wired-condition",
   "metadata": {},
   "source": [
    "## Prepare Data + Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "former-rainbow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RÃ¸dberg is located in the Norwegian traditional district and valley of Numedal .\n",
      "The plants are affiliated with Statkraft , the Norwegian state owned electricity company .\n",
      "The final passenger service ended in 1988 . The rail line north of Rollag was closed in 1989 .\n",
      "\n",
      "Persecution of Jews in Europe increased in the High Middle Ages in the context of the Christian Crusades .\n",
      "In 1394 , 100 , 000 Jews were expelled from France .\n",
      "Jews were indeed infected in numbers similar to their non - Jewish neighbors Yet they were still made scapegoats .\n",
      "Jewish daily life was very satisfying .\n",
      "Jews lived among Jews .\n"
     ]
    }
   ],
   "source": [
    "!cat ./examples/data/text_forward-small.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "restricted-healing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alien-taste",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from newlm.lm.elmo.lm_builder import ELMOLMBuilder\n",
    "\n",
    "from newlm.lm.elmo.modeling_elmo.elmo_head import ELMOBertLMHeadModel\n",
    "from transformers import BertConfig, BertLMHeadModel\n",
    "from newlm.lm.bert.modeling_bert.bert_head import BertLMHeadR2LModel\n",
    "\n",
    "from newlm.utils.file_util import read_from_yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "short-wells",
   "metadata": {},
   "source": [
    "#### Model Bert Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "increased-staff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_l2r = \"./outputs/en.1-percent.bert-causal\"\n",
    "config_l2r = read_from_yaml('examples/configs/run.1-percent-bert-causal.yaml')\n",
    "config_l2r[\"lm\"][\"model_type\"] = 'bert-causal'\n",
    "\n",
    "model_l2r = BertLMHeadModel.from_pretrained(pt_l2r) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "traditional-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_l2r.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reverse-cleaner",
   "metadata": {},
   "outputs": [],
   "source": [
    "pt_r2l = \"./outputs/en.1-percent.bert-causal-r2l\"\n",
    "config_r2l = read_from_yaml('examples/configs/run.1-percent-bert-causal.yaml')\n",
    "config_r2l[\"lm\"][\"model_type\"] = 'bert-causal-r2l'\n",
    "\n",
    "model_r2l = BertLMHeadR2LModel.from_pretrained(pt_r2l) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "pharmaceutical-august",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_r2l.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brown-weather",
   "metadata": {},
   "source": [
    "#### Model ELMO Bert Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "verbal-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./outputs/en.1-percent.elmo-bert-causal/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"ELMOBertLMHeadModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading weights file ./outputs/en.1-percent.elmo-bert-causal/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ELMOBertLMHeadModel.\n",
      "\n",
      "All the weights of ELMOBertLMHeadModel were initialized from the model checkpoint at ./outputs/en.1-percent.elmo-bert-causal.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ELMOBertLMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "pt_elmo = \"./outputs/en.1-percent.elmo-bert-causal\"\n",
    "config_elmo = read_from_yaml('examples/configs/run.1-percent-elmo-bert-causal.yaml')\n",
    "\n",
    "model_elmo = ELMOBertLMHeadModel.from_pretrained(pt_elmo) # use pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "legislative-catch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_elmo.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "latest-repository",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_l2r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "later-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_r2l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-coral",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "weird-firmware",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloader(config_file, tokenizer_dir, model_type, model):\n",
    "    # lm builder (helper)\n",
    "    elmo_lm_builder = ELMOLMBuilder(\n",
    "        model_config = config_file['lm']['model']['config'],\n",
    "        tokenizer=tokenizer_dir,\n",
    "        model_type=model_type,\n",
    "        max_len=128\n",
    "    )\n",
    "    \n",
    "    # dataset-forward\n",
    "    train_path = \"./examples/data/text_forward-small.txt\"\n",
    "    ds_f = elmo_lm_builder._get_dataset(train_path)\n",
    "    \n",
    "    # trainer (helper)\n",
    "    from transformers import TrainingArguments, Trainer\n",
    "    args = TrainingArguments(output_dir=\"tmpout\",**config_file['lm']['hf_trainer']['args'])\n",
    "\n",
    "    # dataloader-forward\n",
    "    trainer = Trainer(model=model, args=args, data_collator=elmo_lm_builder.data_collator, train_dataset=ds_f)\n",
    "    dl_f = trainer.get_train_dataloader() # Data Loader-forward\n",
    "    \n",
    "    \n",
    "    return dl_f, elmo_lm_builder.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "played-uncertainty",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "champion-continent",
   "metadata": {},
   "source": [
    "#### Data for Bert-Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "genetic-mineral",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-08 16:48:32.435 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:145 - Constructing roBERTa style dataset\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/tokenizer.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/added_tokens.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.bert-causal-r2l/tokenizer_config.json. We won't load it.\n",
      "loading file ./outputs/en.1-percent.bert-causal-r2l/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ./outputs/en.1-percent.bert-causal-r2l/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertLMHeadR2LModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading configuration file ./outputs/en.1-percent.bert-causal-r2l/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertLMHeadR2LModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "2022-01-08 16:48:34.213 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:145 - Constructing roBERTa style dataset\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "dl_l2r, tknz_l2r = get_dataloader(config_l2r, pt_l2r, \"bert-causal\", model_l2r)\n",
    "dl_r2l, tknz_r2l = get_dataloader(config_r2l, pt_r2l, \"bert-causal-r2l\", model_r2l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "refined-redhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_l2r = next(iter(dl_l2r))\n",
    "batch_l2r['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "whole-involvement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_r2l = next(iter(dl_r2l))\n",
    "batch_r2l['input_ids'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-script",
   "metadata": {},
   "source": [
    "#### Data for ELMO Bert-Causal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "worst-president",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/tokenizer.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/added_tokens.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/special_tokens_map.json. We won't load it.\n",
      "Didn't find file ./outputs/en.1-percent.elmo-bert-causal/tokenizer_config.json. We won't load it.\n",
      "loading file ./outputs/en.1-percent.elmo-bert-causal/vocab.txt\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading file None\n",
      "loading configuration file ./outputs/en.1-percent.elmo-bert-causal/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"ELMOBertLMHeadModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "loading configuration file ./outputs/en.1-percent.elmo-bert-causal/config.json\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"ELMOBertLMHeadModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": true,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.9.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30000\n",
      "}\n",
      "\n",
      "2022-01-08 16:53:00.172 | INFO     | newlm.lm.elmo.lm_builder:_get_dataset:145 - Constructing roBERTa style dataset\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "dl_elmo, tknz_elmo = get_dataloader(config_elmo, pt_elmo, \"elmo-bert-causal\", model_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "technical-consultation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 127])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_elmo = next(iter(dl_elmo))\n",
    "batch_elmo['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-scholarship",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "instant-welding",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def print_batch(batch_f, tknz):\n",
    "    tokens_f = tknz.convert_ids_to_tokens(batch_f['input_ids'][0])\n",
    "    return pd.DataFrame({\"data\": tokens_f})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "contemporary-infection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>l2r</th>\n",
       "      <th>r2l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##Ã¸</td>\n",
       "      <td>##Ã¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##d</td>\n",
       "      <td>##d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##berg</td>\n",
       "      <td>##berg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>lived</td>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>among</td>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Jews</td>\n",
       "      <td>Jews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[SEP]</td>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        l2r     r2l\n",
       "0     [CLS]   [CLS]\n",
       "1         R       R\n",
       "2       ##Ã¸     ##Ã¸\n",
       "3       ##d     ##d\n",
       "4    ##berg  ##berg\n",
       "..      ...     ...\n",
       "122   lived   lived\n",
       "123   among   among\n",
       "124    Jews    Jews\n",
       "125       .       .\n",
       "126   [SEP]   [SEP]\n",
       "\n",
       "[127 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_l2r = print_batch(batch_l2r, tknz_l2r)\n",
    "df_r2l = print_batch(batch_r2l, tknz_r2l)\n",
    "pd.DataFrame({\"l2r\": df_l2r['data'], \"r2l\": df_r2l[\"data\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "universal-failing",
   "metadata": {},
   "source": [
    "Same input (forward) for L2R and R2L. The R2L input would be flipped inside forward method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "german-manufacturer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[CLS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>##Ã¸</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>##d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>##berg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>lived</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>among</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>Jews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>[SEP]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>127 rows Ã 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       data\n",
       "0     [CLS]\n",
       "1         R\n",
       "2       ##Ã¸\n",
       "3       ##d\n",
       "4    ##berg\n",
       "..      ...\n",
       "122   lived\n",
       "123   among\n",
       "124    Jews\n",
       "125       .\n",
       "126   [SEP]\n",
       "\n",
       "[127 rows x 1 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print_batch(batch_elmo, tknz_elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-aaron",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "grave-lobby",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model in eval mode for consistency\n"
     ]
    }
   ],
   "source": [
    "model_elmo.eval()\n",
    "model_l2r.eval()\n",
    "model_r2l.eval()\n",
    "print(\"Model in eval mode for consistency\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharing-person",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "stainless-hotel",
   "metadata": {},
   "source": [
    "## Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ongoing-mason",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2r_loss tensor(4.3849, grad_fn=<NllLossBackward>)\n",
      "r2l_loss tensor(4.4385, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "res_l2r = model_l2r(**batch_l2r)\n",
    "print(\"l2r_loss\", res_l2r.loss)\n",
    "\n",
    "res_r2l = model_r2l(**batch_r2l)\n",
    "print(\"r2l_loss\", res_r2l.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "collectible-custody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP Bert-Causal l2r tensor([80.2302])\n",
      "PP Bert-Causal r2l tensor([84.6479])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"PP Bert-Causal l2r\", torch.exp(torch.Tensor([4.3849])))\n",
    "print(\"PP Bert-Causal r2l\", torch.exp(torch.Tensor([4.4385])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-shape",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "posted-contribution",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2r_loss tensor(4.4801, grad_fn=<NllLossBackward>)\n",
      "r2l_loss tensor(4.3589, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#### ELMO BERT-Causal\n",
    "res_elmo = model_elmo(**batch_elmo) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bibliographic-spoke",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PP ELMO Bert-Causal l2r tensor([88.2435])\n",
      "PP ELMO Bert-Causal r2l tensor([78.1711])\n"
     ]
    }
   ],
   "source": [
    "print(\"PP ELMO Bert-Causal l2r\", torch.exp(torch.Tensor([4.4801])))\n",
    "print(\"PP ELMO Bert-Causal r2l\", torch.exp(torch.Tensor([4.3589])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
